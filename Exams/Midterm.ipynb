{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "header"
   },
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h1>The University of North Carolina at Chapel Hill</h1>\n",
    "<h1>Comp 555 BioAlgorithms - Spring 2019</h1>\n",
    "<h1 style=\"font-size: 250%;\">Midterm Exam</h1>\n",
    "<h1>Thursday March 7, 2019</h1>\n",
    "</div>\n",
    "\n",
    "**Instructions:** Answer all questions using the cells provided. Feel free to add additional cells to your notebook, but there is no guarantee that they will be considered when grading. If any question seems unclear or appears to lack sufficient information, state a reasonable assumption in the cell provided for your answer and proceed.\n",
    "\n",
    "You can use any notes, books, or on-line materials to aid when answering your questions, so long as they do not involve communication with any other person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The following three problems refer to the following 1000-base dna sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"CGGTTCGATCCCGCTAGGCTCCATCAGGATACAATCCTACTAAACTTAATACAAGTGAAGTTGAACACGCAACTCACTTCCTAGGAAAATGGACAATCTT\" \\\n",
    "    + \"CCCTTGTGTGCAAGGCCCACATGGTCAGATTCCTAATTTTCTACAGAAGTTTCGCTAAAGCGAGCGTTGCTTAGTATCCTATATAATAGTCCATTGAAAA\" \\\n",
    "    + \"TTGAATATCTATATCAAATTCCACGATCTAGAAATAGATTGTAGAAAAGTAACAAGAAAATAAACCGAAAACGCTGTGACTATTTAATAAGTTTTCTAGT\" \\\n",
    "    + \"TTAAAAAAACTAGGTTAATAAGGTTAAGTTAATAAGGGCGCACGGTGGATGCCTTGGCACTAGAAGCCGAAGAAGGACGTGACTAACGACGAAATGCTTT\" \\\n",
    "    + \"GGGGAGCTGTAAGTAAGCGCTGATCCAGAGATGTCCGAATGGGGGAACCCGGCATGTAATGCATGTCATCCATGACTGTTAAGGTCATGAGAAGGAAGAC\" \\\n",
    "    + \"GCAGTGAACTGAAACATCTAAGTAGCTGCAGGAAGAGAAAGCAAACGCGATTGCCTTAGTAGCGGCGAGCGAAACGGCAGGAGGGCAAACCGAGGAGTTT\" \\\n",
    "    + \"ACTCCTCGGGGTTGTAGGACTGCGAAGTGGGACATAAAGTTAATAGAAGAATTACCTGGGAAGGTAAGCCAAAGAGAGTAACAGCCTCGTATTTAAAATT\" \\\n",
    "    + \"GACTTTAGCCCTAGCAGTATCCTGAGTACGGCGAGACACGCGAAATCTCGTCGGAATCTGGGAGGACCATCTCCCAACCCTAAATACTCTCTAGTGACCG\" \\\n",
    "    + \"ATAGTGAACCAGTACCGTGAGGGAAAGGTGAAAAGCACCCCGGGAGGGGAGTGAAATAGAACCTGAAACCGTGTGCCTACAACAAGTTCGAGCCCGTTAA\" \\\n",
    "    + \"TGGGTGAGAGCGTGCCTTTTGTAGAATGAACCGGCGAGTTACGATATGATGCGAGGTTAAGTTGAAGAGACGGAGCCGTAGGGAAACCGAGTCTTAATAG\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = seq[0]\n",
    "def kmerCounts(seq, k):\n",
    "    kmerDict = {}\n",
    "    for i in range(1,len(seq)-k+1):\n",
    "        kmer = seq[i:i+k]\n",
    "        kmerDict[kmer] = kmerDict.get(kmer,0) + 1\n",
    "    return kmerDict\n",
    "\n",
    "print('  k     k-mers              4^k      N-k+1          missing   repeated')\n",
    "for k in range(2,25):\n",
    "    kmers = kmerCounts(seq, k)\n",
    "    print(\"%3d %10d %16d %10d %16d %10d\" % (k, len(kmers), 4**k, (len(seq)-1)-k+1, 4**k-len(kmers), (len(seq)-1)-k+1-len(kmers)))\n",
    "    \n",
    "kmers = kmerCounts(seq, 4)\n",
    "    \n",
    "def printAllKLength(set, k): \n",
    "    n = len(set)  \n",
    "    printAllKLengthRec(set, \"\", n, k) \n",
    "  \n",
    "def printAllKLengthRec(set, prefix, n, k): \n",
    "      \n",
    "    # Base case: k is 0, \n",
    "    # print prefix \n",
    "    if (k == 0) : \n",
    "#         print(prefix)\n",
    "        all_kmers.append(prefix)\n",
    "        return\n",
    "  \n",
    "    # One by one add all characters  \n",
    "    # from set and recursively  \n",
    "    # call for k equals to k-1 \n",
    "    for i in range(n): \n",
    "  \n",
    "        # Next character of input added \n",
    "        newPrefix = prefix + set[i] \n",
    "          \n",
    "        # k is decreased, because  \n",
    "        # we have added a new character \n",
    "        printAllKLengthRec(set, newPrefix, n, k - 1)\n",
    "all_kmers = []\n",
    "set1 = ['A','C','G','T']\n",
    "printAllKLength(set1, 4)\n",
    "# print(all_kmers)\n",
    "print(\"\\n\\n4 missing kmers:\")\n",
    "print(list(set(all_kmers) - set(kmers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 1,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #1:** What is the smallest value of *k* where *seq* does not contain every possible *k*-mer? Give a list of all missing *k*-mers for that value of k."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 1,
    "section": "answer"
   },
   "source": [
    "Enter your value of k and list of missing k-mers here.\n",
    "Missing > 0\n",
    "\n",
    "\n",
    "   k     k-mers              4^k      N-k+1          missing   repeated\n",
    "\n",
    "k=4:        252              256        996                4        744\n",
    "\n",
    "4 missing kmers:\n",
    "['ATCG', 'CGCC', 'TTAT', 'TTCA']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 2,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #2:** What is the smallest value of *k* where every *k*-mer in *seq* is distinct (i.e. it contains no repeated *k*-mers)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 2,
    "section": "answer"
   },
   "source": [
    "Enter your value of k here.\n",
    "\n",
    "    k     k-mers              4^k      N-k+1          missing   repeated\n",
    "k=11:        989          4194304        989          4193315          0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 3,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #3:** Suppose that you constructed a De Bruijn graph using all *k*-mers from *seq*, with *k* set to one larger than your solution to **Problem #2**. What would be the maximum in-degree and out-degree for any vertex in this graph? Explain your answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, vlist=[]):\n",
    "        \"\"\" Initialize a Graph with an optional vertex list \"\"\"\n",
    "        self.index = {v:i for i,v in enumerate(vlist)}\n",
    "        self.vertex = {i:v for i,v in enumerate(vlist)}\n",
    "        self.edge = []\n",
    "        self.edgelabel = []\n",
    "    def addVertex(self, label):\n",
    "        \"\"\" Add a labeled vertex to the graph \"\"\"\n",
    "        index = len(self.index)\n",
    "        self.index[label] = index\n",
    "        self.vertex[index] = label\n",
    "    def addEdge(self, vsrc, vdst, label='', repeats=True):\n",
    "        \"\"\" Add a directed edge to the graph, with an optional label. \n",
    "        Repeated edges are distinct, unless repeats is set to False. \"\"\"\n",
    "        e = (self.index[vsrc], self.index[vdst])\n",
    "        if (repeats) or (e not in self.edge):\n",
    "            self.edge.append(e)\n",
    "            self.edgelabel.append(label)\n",
    "    def hamiltonianPath(self):\n",
    "        \"\"\" A Brute-force method for finding a Hamiltonian Path. \n",
    "        Basically, all possible N! paths are enumerated and checked\n",
    "        for edges. Since edges can be reused there are no distictions\n",
    "        made for *which* version of a repeated edge. \"\"\"\n",
    "        for path in itertools.permutations(sorted(self.index.values())):\n",
    "            for i in xrange(len(path)-1):\n",
    "                if ((path[i],path[i+1]) not in self.edge):\n",
    "                    break\n",
    "            else:\n",
    "                return [self.vertex[i] for i in path]\n",
    "        return []\n",
    "    def SearchTree(self, path, verticesLeft):\n",
    "        \"\"\" A recursive Branch-and-Bound Hamiltonian Path search. \n",
    "        Paths are extended one node at a time using only available\n",
    "        edges from the graph. \"\"\"\n",
    "        if (len(verticesLeft) == 0):\n",
    "            self.PathV2result = [self.vertex[i] for i in path]\n",
    "            return True\n",
    "        for v in verticesLeft:\n",
    "            if (len(path) == 0) or ((path[-1],v) in self.edge):\n",
    "                if self.SearchTree(path+[v], [r for r in verticesLeft if r != v]):\n",
    "                    return True\n",
    "        return False\n",
    "    def hamiltonianPathV2(self):\n",
    "        \"\"\" A wrapper function for invoking the Branch-and-Bound \n",
    "        Hamiltonian Path search. \"\"\"\n",
    "        self.PathV2result = []\n",
    "        self.SearchTree([],sorted(self.index.values()))                \n",
    "        return self.PathV2result\n",
    "    def degrees(self):\n",
    "        \"\"\" Returns two dictionaries with the inDegree and outDegree\n",
    "        of each node from the graph. \"\"\"\n",
    "        inDegree = {}\n",
    "        outDegree = {}\n",
    "        for src, dst in self.edge:\n",
    "            outDegree[src] = outDegree.get(src, 0) + 1\n",
    "            inDegree[dst] = inDegree.get(dst, 0) + 1\n",
    "        return inDegree, outDegree\n",
    "    def verifyAndGetStart(self):\n",
    "        inDegree, outDegree = self.degrees()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for vert in self.vertex.keys():\n",
    "            ins = inDegree.get(vert,0)\n",
    "            outs = outDegree.get(vert,0)\n",
    "            if (ins == outs):\n",
    "                continue\n",
    "            elif (ins - outs == 1):\n",
    "                end = vert\n",
    "            elif (outs - ins == 1):\n",
    "                start = vert\n",
    "            else:\n",
    "                start, end = -1, -1\n",
    "                break\n",
    "        if (start >= 0) and (end >= 0):\n",
    "            return start\n",
    "        else:\n",
    "            return -1\n",
    "    def eulerianPath(self):\n",
    "        graph = [(src,dst) for src,dst in self.edge]\n",
    "        currentVertex = self.verifyAndGetStart()\n",
    "        path = [currentVertex]\n",
    "        # \"next\" is where vertices get inserted into our tour\n",
    "        # it starts at the end (i.e. it is the same as appending),\n",
    "        # but later \"side-trips\" will insert in the middle\n",
    "        next = 1\n",
    "        while len(graph) > 0:\n",
    "            for edge in graph:\n",
    "                if (edge[0] == currentVertex):\n",
    "                    currentVertex = edge[1]\n",
    "                    graph.remove(edge)\n",
    "                    path.insert(next, currentVertex)\n",
    "                    next += 1\n",
    "                    break\n",
    "            else:\n",
    "                for edge in graph:\n",
    "                    try:\n",
    "                        next = path.index(edge[0]) + 1\n",
    "                        currentVertex = edge[0]\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                else:\n",
    "                    print(\"There is no path!\")\n",
    "                    return False\n",
    "        return path\n",
    "    def eulerEdges(self, path):\n",
    "        edgeId = {}\n",
    "        for i in range(len(self.edge)):\n",
    "            edgeId[self.edge[i]] = edgeId.get(self.edge[i], []) + [i]\n",
    "        edgeList = []\n",
    "        for i in range(len(path)-1):\n",
    "            edgeList.append(self.edgelabel[edgeId[path[i],path[i+1]].pop()])            \n",
    "        return edgeList\n",
    "    def render(self, highlightPath=[]):\n",
    "        \"\"\" Outputs a version of the graph that can be rendered\n",
    "        using graphviz tools (http://www.graphviz.org/).\"\"\"\n",
    "        edgeId = {}\n",
    "        for i in xrange(len(self.edge)):\n",
    "            edgeId[self.edge[i]] = edgeId.get(self.edge[i], []) + [i]\n",
    "        edgeSet = set()\n",
    "        for i in xrange(len(highlightPath)-1):\n",
    "            src = self.index[highlightPath[i]]\n",
    "            dst = self.index[highlightPath[i+1]]\n",
    "            edgeSet.add(edgeId[src,dst].pop())\n",
    "        result = ''\n",
    "        result += 'digraph {\\n'\n",
    "        result += '   graph [nodesep=2, size=\"10,10\"];\\n'\n",
    "        for index, label in self.vertex.iteritems():\n",
    "            result += '    N%d [shape=\"box\", style=\"rounded\", label=\"%s\"];\\n' % (index, label)\n",
    "        for i, e in enumerate(self.edge):\n",
    "            src, dst = e\n",
    "            result += '    N%d -> N%d' % (src, dst)\n",
    "            label = self.edgelabel[i]\n",
    "            if (len(label) > 0):\n",
    "                if (i in edgeSet):\n",
    "                    result += ' [label=\"%s\", penwidth=3.0]' % (label)\n",
    "                else:\n",
    "                    result += ' [label=\"%s\"]' % (label)\n",
    "            elif (i in edgeSet):\n",
    "                result += ' [penwidth=3.0]'                \n",
    "            result += ';\\n'                \n",
    "        result += '    overlap=false;\\n'\n",
    "        result += '}\\n'\n",
    "        return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 3,
    "section": "answer"
   },
   "source": [
    "Enter your answer and explanation here.\n",
    "*******\n",
    "Using the code I found the max in and out degree to be 2. (2,2).\n",
    "\n",
    "The maximum in and out degree should be small (near 1). Since there are no repeated kmers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 4,
    "section": "problem"
   },
   "source": [
    "---\n",
    "In the following two problems assume you are given 100 sequences each 1000 base pairs long and asked to find a 10-base motif for a binding site of a transcription-factor known to interact with each of the given sequences.\n",
    "\n",
    "**Problem #4:** Suppose you are told that no binding site can differ in more than 1 position from the optimal motif. How might this contraint impact your search strategy? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 4,
    "section": "answer"
   },
   "source": [
    "Enter your answer here.\n",
    "\n",
    "You can make sure that the minimum hamming distance is less than 2 from the median string motif. \n",
    "\n",
    "The minimal hamming distance corresponds to the number of positions that are different between two strings. \n",
    "\n",
    "So, after finding the median string motif, or the motif that a string that minimizes Hamming distance, like finding a middle or median string that is closer to all instances than the instances are to each other, we can just check if the minimal hamming distance between the optimal motif and all other motifs is less than 2 (meaning no binding site differs in more than 1 position from the optimal motif). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 5,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #5** Suppose you are told to only consider motif's that are their own reverse complement. For example, the reverse complement of *GAGCATGCTC* is *GAGCATGCTC*. How would you incorporate this constraint into your search strategy?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 5,
    "section": "answer"
   },
   "source": [
    "Enter your answer here.\n",
    "Is the reverse compliment always the same as the string?\n",
    "\n",
    "I would use the MedianStringMotifSearch().\n",
    "When calculating the ScanAndScoreMotif() we calculate it using:\n",
    "    HammingDist = sum([1 for i in range(k) if motif[i] != seq[s+i]])\n",
    "    \n",
    "I would create a new metric that is very similar to the Hamming Distance, but calculates the number of positions that are different a string and its reverse compliment. \n",
    "I would create a function called ReverseCompliment() that takes a string as an input, and returns the reverse compliment of it. Then use it like this:\n",
    "    NewhammingDist = sum([1 for i in range(k) if motif[i] != ReverseCompliment(seq[s+i]]) )\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The following problems refer to the following multi-string Burrows-Wheeler Transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msBWT = \"TCAATGATAATGCCTTTTTTTTTTTAGGGTGAGAGGGGAAAAAAAAATACAAAATAACACAGCCCACACCCCTCCCAAAAAAAAAAATTAAATCATACAA\" \\\n",
    "      + \"AATATAAGAATTTATAAGGATATCAAAAAATGCGAAAATAAGATTTTGAAGCAAAAGAAGAGTGAATGAAATTGAGGCCAAAGGAGAAACGACTCATTTT\" \\\n",
    "      + \"GGGCCCCTGCGGGGGGAAGGGTTCTTTCCCTGTGGACAGGCTTAAAGGGTTATACATAGCTAAGACGTACGAGTGGAATCAAGGGTAAACTAAAAACGAA\" \\\n",
    "      + \"AATGAAAATAGAAGACCCAGATGAAGTATAATTTTGTAAAAAAAGAGGATGAGTAAAAGAATTGTATGGGATAAGCCCCGGGAGGAGCCCTCTTTAAAAG\" \\\n",
    "      + \"ACAAGAATCTAACGGTGGACGAAACTGCAATCGAGGAAAGGACAGTCCCAAAACACTCTTAAAGAGCCTCTAAATGATTTTGGAACAAGGAAAAAAATTG\" \\\n",
    "      + \"GCAAAGGGAAATTCGCAAATAAATAACATATAAAAGGAAAGAATGATGAAAAAAACAAATCAATATCAGGTAAGCTAAGGAAAAAGAAAGTAGGTGATTG\" \\\n",
    "      + \"ACAGCGCCCTGGGGACAAGGAAATAAAAAGTTAAAGGAGAGTGGAAATGGGGAAGGGGTGAGTTGGTAAAGAATACTACAAAAAACTATATACCCGGTTT\" \\\n",
    "      + \"TGCCAAAAGGTAGATATCGCAACGGAAAAAACGGAGACGATGAAAGCATGCCATTCGTCTAAGGGAAAAAGGGAACCAAACTAAATACATAATAGGGAAA\" \\\n",
    "      + \"AGATCGAAGCATCAAAAGAATTGATAATATTTAAAATTGGAAAAACGAAAATAATTGTTTAATTTGTTGTGTAACACTTTTTTTAAGGCAACAATGACTT\" \\\n",
    "      + \"AGGAATAAACATAAACAGATAGATTAAAAATTTCTCCTATGTAAAGGGTTTTA$AAAGAGTAATGACAGAATAAATGGAGGGAAATAGTCCG$ATCACAA\" \\\n",
    "      + \"AAGTATAAAAA$A$AGAGAAGAAATGACATCGGGCAA$AAAGAGGGGCGAAAATTTCATCACGAAAACAAGAGGTAGAAGATTGACATAAAAAAAAACAT\" \\\n",
    "      + \"GACCTATTTTTTTTAATTTAAACTGAAATTTTTTAACTGGCTTTTTTTATCCAAAGTCCAATGATGTTTGTAAATACTTCGTGACCGTTTCGTCCCCAAA\" \\\n",
    "      + \"ATATTTAAATATACGGGTCTGCGACGGGATCCACAGAGTATATACTAACAATACAGATTTGAAAAAATATCAAACAGAATACCCCCAAAATGCGTTTGAG\" \\\n",
    "      + \"TTAGTTCAAGAACCACCTTCAGATGCAAGCTGGGAACCAGGCCG$TCGGGGAACGGGAATGGTGAAGGGG$$GACAATTATCGGCCCACTTTCCGTGGCA\" \\\n",
    "      + \"TGAGGACCCTAG\"\n",
    "print(\"Length of string:\" ,len(msBWT))\n",
    "print(\"Num $s:\",msBWT.count(\"$\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FMIndex(bwt):\n",
    "    fm = [{c: 0 for c in bwt}]\n",
    "    for c in bwt:\n",
    "        row = {symbol: count + 1 if (symbol == c) else count for symbol, count in fm[-1].items()}\n",
    "        fm.append(row)\n",
    "    offset = {}\n",
    "    N = 0\n",
    "    for symbol in sorted(row.keys()):\n",
    "        offset[symbol] = N\n",
    "        N += row[symbol]\n",
    "    return fm, offset\n",
    "\n",
    "# def mergeBWT(bwt1, bwt2):\n",
    "#     interleave = [(c, 0) for c in bwt1] + [(c, 1) for c in bwt2]\n",
    "#     passes = min(len(bwt1), len(bwt2))\n",
    "#     for p in range(passes):\n",
    "#         i, j = 0, 0\n",
    "#         nextInterleave = []\n",
    "#         for c, k in sorted(interleave, key=lambda x: x[0]):\n",
    "#             if (k == 0):\n",
    "#                 b = bwt1[i]\n",
    "#                 i += 1\n",
    "#             else:\n",
    "#                 b = bwt2[j]\n",
    "#                 j += 1\n",
    "#             nextInterleave.append((b, k))\n",
    "#         if (nextInterleave == interleave):\n",
    "#             break\n",
    "#         interleave = nextInterleave\n",
    "#     return ''.join([c for c, k in interleave])\n",
    "def recoverSuffix(i, BWT, FMIndex, Offset):\n",
    "    suffix = ''\n",
    "    c = BWT[i]\n",
    "    predec = Offset[c] + FMIndex[i][c]\n",
    "    suffix = c + suffix\n",
    "    while (predec != i):\n",
    "        c = BWT[predec]\n",
    "        predec = Offset[c] + FMIndex[predec][c]\n",
    "        suffix = c + suffix\n",
    "    return suffix\n",
    "\n",
    "# bwt1 = \"TG$TC$AAAA\"\n",
    "# bwt2 = \"AAGTGTA$A$\"\n",
    "# bwt12 = mergeBWT(bwt1, bwt2)\n",
    "# print(bwt12)\n",
    "FM, Offset = FMIndex(msBWT)\n",
    "# print(len(bwt12))\n",
    "print(\"Num Strings:\",round(1412/178))\n",
    "for i in range(len(msBWT)):\n",
    "    recover = recoverSuffix(i,msBWT,FM,Offset)\n",
    "    print(i, \": \", recover, len(recover))\n",
    "#     j = (i>>2)+(i&3)*(len(bwt12)//4)\n",
    "#     print(\"%2d: %s\" % (j, recoverSuffix(j,msBWT,FM,Offset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 6,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #6.** How many strings are encoded in this msBWT and are all strings of a uniform length? Explain how you arrived at your answers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 6,
    "section": "answer"
   },
   "source": [
    "Enter your answers to Problem 6 here.\n",
    "Length of string: 1412\n",
    "Num $s: 8\n",
    "Length of suffix: 178\n",
    "--\n",
    "\n",
    "there are 1412 characters in this msBWT and the number of characters in the msBWT corresponds to the number of suffixes. They are not the same length. Since the number of suffixes is equal to the length of the suffix, there should be 178 suffixes per string. \n",
    "So, there are 8 strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 7,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #7.** How many times does the substring *\"TAAAAAC\"* appear in the strings of the given msBWT? Does *\"TAAAAAC\"* appear in all of the encoded strings? Explain how you arrived at your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBWT(pattern, FMIndex, Offset):\n",
    "    lo = 0\n",
    "    hi = len(FMIndex) - 1\n",
    "    for symbol in reversed(pattern):\n",
    "        lo = Offset[symbol] + FMIndex[lo][symbol]\n",
    "        hi = Offset[symbol] + FMIndex[hi][symbol]\n",
    "    return lo, hi\n",
    "print(\"FM:\",FM)\n",
    "print(\"Offset:\",Offset)\n",
    "print(\"FM[1]:\", FM[4])\n",
    "# print(len(FM))\n",
    "\n",
    "def findFirst(pattern, text, suffixarray):\n",
    "    lo, hi = 0, len(text)\n",
    "    while (lo < hi):\n",
    "        middle = (lo+hi)//2\n",
    "        if text[suffixarray[middle]:] < pattern:\n",
    "            lo = middle + 1\n",
    "        else:\n",
    "            hi = middle\n",
    "    return lo\n",
    "\n",
    "def findLast(pattern, text, suffixarray):\n",
    "    lo, hi = 0, len(text)\n",
    "    while (lo < hi):\n",
    "        middle = (lo+hi)//2\n",
    "        if text[suffixarray[middle]:suffixarray[middle]+len(pattern)] <= pattern:\n",
    "            lo = middle + 1\n",
    "        else:\n",
    "            hi = middle\n",
    "    return lo\n",
    "\n",
    "print(findBWT(\"TAAAAAC\", FM, Offset))\n",
    "last = findLast(\"an\", t, sa)\n",
    "print(first, last)\n",
    "for suffix in sa[first:last]:     # recall \"first\" was found on the previous slide\n",
    "    print(\"%3d: %s\" % (suffix, t[suffix:]))\n",
    "print(last - first, \"times\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 7,
    "section": "answer"
   },
   "source": [
    "Enter your answers to Problem 7 here.\n",
    "---\n",
    "\n",
    "The substring appears 1 time\n",
    "It does not appear in all encoded strings. \n",
    "It only appears in the 3rd encoded string. \n",
    "Used findFirst and findLast methods then returning the last - first to get the appear count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 8,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #8.** In an uncompressed msBWT each character is the predecessor of the suffix array of the encoded set of strings. *Describe an algorithm* to find the *sucessor* character of each string of the suffix array (the second letter of each suffix). You can assume that a full FMindex and offset list are available. *Estimate the performance of your algorithm*."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 8,
    "section": "answer"
   },
   "source": [
    "Describe your algorithm and its performance. You may provide Python code if you wish, but a clear description will suffice.\n",
    "BWT are O(search text) in storage, O(lenght of pattern) in single search, O(num patterns * lenght of pattern) in multiple searches. \n",
    "MSBWT:\n",
    "Arbitrary exact-match k-mer queries\n",
    "● O(k) time\n",
    "Recover an arbitrary read of length L from MSBWT\n",
    "● O(L) time\n",
    "---\n",
    "\n",
    "(out of time)\n",
    "\n",
    "The algorithm will be very similar to the BWT, but with multiple strings. \n",
    "The BWT algorithm is simple/implemented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 9,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem #9**. How well does the successor character of each string from a suffix array compress in comparision to the msBWT? Does the first-last property apply to this string of sucessor characters? Explain your answers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 9,
    "section": "answer"
   },
   "source": [
    "Enter your answers and explanations here.\n",
    "\n",
    "____\n",
    "\n",
    "(out of time)\n",
    "\n",
    "\n",
    "It should compress it very well, because the msBWT groups similar characters together. \n",
    "The first-last property applies sincei ts a msBWT. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
